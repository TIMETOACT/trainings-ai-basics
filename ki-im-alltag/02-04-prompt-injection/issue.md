---
layout: default
title: √úbung (Prompt Injection)
parent: 02-04 Prompt Injection
nav_order: 1
---

# √úbung (Prompt Injection): Angriff auf den Agenten

Ich m√∂chte verstehen, welche Sicherheitsrisiken bei der Verwendung von Agenten, insbesondere durch manipulative Eingaben (Prompt Injection), bestehen und wie man diese vermeiden kann.

## üéØ Lernziele
*   Du lernst, was man unter Prompt Injection versteht.
*   Du verstehst die verschiedenen Angriffsvektoren (direkt, indirekt, etc.).
*   Du entwickelst ein Bewusstsein f√ºr notwendige Schutzma√ünahmen.

## ü™ú Arbeitsschritte
1.  **Recherche:** F√ºhre eine Eigenrecherche zum Thema "Prompt Injection" durch und beantworte die folgenden Fragen:
    1.1 Was ist Prompt Injection?
    1.2 Wie funktioniert Prompt Injection?
    1.3 Wo kann Prompt Injection angreifen?
    1.4 Wie kann man Prompt Injection vermeiden?
2.  **Visualisierung:** Nutze die bereitgestellte [Agent Architecture Visualisierung](agent-architecture-visualisierung.html) als Lernhilfe. Untersuche, an welchen Stellen der Architektur Angriffe ansetzen k√∂nnten.

## ‚úÖ Definition of Done
*   [ ] Du hast 3 Beispiele f√ºr Prompt Injection identifiziert und verstanden.
*   [ ] Du hast die Reflexionsfragen schriftlich beantwortet.

## ü§î Reflexionsfragen
*   Warum sind Agenten, die Zugriff auf E-Mails oder Webseiten haben, besonders gef√§hrdet f√ºr "indirekte Prompt Injection"?
*   Ist es m√∂glich, ein LLM zu 100% gegen Prompt Injection zu sch√ºtzen? (Begr√ºnde deine Antwort)
